<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective">
  <!-- <meta name="keywords" content="Guru, Reinforcement Learning, LLMs, General Reasoning, Cross-Domain Generalization, AI"> -->
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective</title>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL-TODO"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL-TODO');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/guru_favicon.png">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>

  <!-- Custom styles for results table -->
  <style>
    /* Center align and middle vertical align */
    #results-table th,
    #results-table td {
      text-align: center;
      vertical-align: middle;
      font-size: 0.85rem;
    }

    /* Highlight Guru columns (1-based index) */
    #results-table .guru-col {
      background-color: #d0e7ff !important; /* light blue, !important to override other styles */
      font-weight: bold;
    }

    /* Header background */
    #results-table thead th {
      background-color: #e4eefb;
      font-weight: 700;
    }

    /* Section header rows (domain separators) */
    #results-table tr.section-header th {
      background-color: #f5f5f5;
      text-align: left;
      font-weight: 700;
    }

    /* Average row */
    #results-table tr.average-row td,
    #results-table tr.average-row th {
      font-weight: 700;
    }

    /* Styles for the new dataset stats table */
    #dataset-stats-table {
      margin-top: 2rem;
      border: 1px solid #dbdbdb;
    }
    #dataset-stats-table th,
    #dataset-stats-table td {
      vertical-align: middle;
    }
    #dataset-stats-table thead th {
      text-align: center;
      background-color: #f5f5f5;
    }
    #dataset-stats-table tbody th {
      font-weight: bold;
    }
    #dataset-stats-table td {
      text-align: right;
    }
    #dataset-stats-table .dataset-col {
      text-align: left;
    }
    #dataset-stats-table .centered-col {
      text-align: center;
    }
    #dataset-stats-table .percent {
      color: #7a7a7a;
      font-size: 0.8em;
      display: block;
      text-align: center;
    }
    #dataset-stats-table tfoot tr {
      background-color: #e3f2fd;
    }
    #dataset-stats-table tfoot th,
    #dataset-stats-table tfoot td {
      font-weight: bold;
    }

    /* Author styling */
    .publication-authors-section {
      font-size: 1rem;
    }
    
    .author-name {
      display: inline-block;
      margin-right: 0.75rem;
      margin-bottom: 0.25rem;
      font-weight: 500;
    }
    
    .author-name:last-child {
      margin-right: 0;
    }
    
    .author-row {
      text-align: center;
    }
    
    .affiliation {
      font-weight: 600;
      color: #333;
    }
    
    .equal-contribution {
      text-align: center;
    }
    
    /* Responsive design for authors */
    @media (max-width: 768px) {
      .author-row {
        font-size: 0.9rem;
        line-height: 1.4;
      }
      
      .affiliation-list {
        flex-direction: column;
        gap: 0.5rem !important;
      }
    }
  </style>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#Guru-project-home-TODO">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://www.llm360.ai/">
            LLM360: A fully-reproducible large language model
          </a>
          <a class="navbar-item" href="https://github.com/maitrix-org/llm-reasoners">
            LLM-Reasoners: A library for LLM complex reasoning
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-2 publication-title">Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective</h1>
          <!-- Authors Section -->
          <div class="publication-authors-section" style="margin-top: 1.5rem; margin-bottom: 2rem;">
            <!-- Authors List -->
            <div class="authors-list" style="line-height: 1.6; margin-bottom: 1.5rem;">
              <div class="author-row" style="margin-bottom: 0.5rem;">
                <span class="author-name">Zhoujun Cheng<sup>1,*</sup></span>,
                <span class="author-name">Shibo Hao<sup>1,*</sup></span>,
                <span class="author-name">Tianyang Liu<sup>1,*</sup></span>,
                <span class="author-name">Fan Zhou<sup>2</sup></span>,
                <span class="author-name">Yutao Xie<sup>1</sup></span>,
                <span class="author-name">Feng Yao<sup>1</sup></span>
              </div>
              <div class="author-row" style="margin-bottom: 0.5rem;">
                <span class="author-name">Yuexin Bian<sup>1</sup></span>,
                <span class="author-name">Yonghao Zhuang<sup>3</sup></span>,
                <span class="author-name">Nilabjo Dey<sup>4</sup></span>,
                <span class="author-name">Yuheng Zha<sup>1</sup></span>,
                <span class="author-name">Yi Gu<sup>1</sup></span>,
                <span class="author-name">Kun Zhou<sup>1</sup></span>
              </div>
              <div class="author-row" style="margin-bottom: 0.5rem;">
                <span class="author-name">Yuqi Wang<sup>2</sup></span>,
                <span class="author-name">Yuan Li<sup>3</sup></span>,
                <span class="author-name">Richard Fan<sup>2</sup></span>,
                <span class="author-name">Jianshu She<sup>2</sup></span>,
                <span class="author-name">Chengqian Gao<sup>2</sup></span>,
                <span class="author-name">Abulhair Saparov<sup>4</sup></span>
              </div>
              <div class="author-row">
                <span class="author-name">Haonan Li<sup>2</sup></span>,
                <span class="author-name">Taylor W. Killian<sup>2</sup></span>,
                <span class="author-name">Mikhail Yurochkin<sup>2</sup></span>,
                <span class="author-name">Zhengzhong Liu<sup>2</sup></span>,
                <span class="author-name">Eric P. Xing<sup>2,3</sup></span>,
                <span class="author-name">Zhiting Hu<sup>1</sup></span>
              </div>
            </div>
            
            <!-- Affiliations -->
            <div class="affiliations" style="margin-bottom: 1rem;">
              <div class="affiliation-list" style="display: flex; justify-content: center; flex-wrap: wrap; gap: 1.5rem; margin-bottom: 0.75rem;">
                <span class="affiliation"><sup>1</sup>UC San Diego</span>
                <span class="affiliation"><sup>2</sup>MBZUAI</span>
                <span class="affiliation"><sup>3</sup>Carnegie Mellon University</span>
                <span class="affiliation"><sup>4</sup>Purdue University</span>
              </div>
              <div class="equal-contribution" style="font-style: italic; color: #666; font-size: 0.9rem;">
                <sup>*</sup>Equal Contribution
              </div>
            </div>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="https://arxiv.org/abs/2506.14965" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Arxiv</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://github.com/LLM360/Reasoning360"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>GitHub</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/datasets/LLM360/guru-RL-92k"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="far fa-images"></i></span>
                  <span>Data</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://huggingface.co/LLM360/guru-7B"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-lightbulb"></i></span>
                  <span>Model</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <div class="columns is-centered" style="margin-bottom: 1rem;">
        <div class="column is-half">
          <img src="./static/images/fig1a.svg" alt="Figure 1a" style="width: 100%; height: auto;">
        </div>
        <div class="column is-half">
          <img src="./static/images/fig1b_v3.svg" alt="Figure 1b" style="width: 100%; height: auto;">
        </div>
      </div>
      <h2 class="subtitle has-text-centered">
        <b>Guru</b> introduces a curated 92K multi-domain RL-for-reasoning dataset and models, enabling a systematic study of cross-domain RL and achieving strong general reasoning performance.  </h2>    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Reinforcement learning (RL) has emerged as a promising approach to improve large language model (LLM) reasoning, yet most open efforts focus narrowly on math and code, limiting our understanding of its broader applicability to general reasoning. 
            A key challenge lies in the lack of reliable, scalable RL reward signals across diverse reasoning domains.
            We introduce Guru, a curated RL reasoning corpus of 92K verifiable examples spanning six reasoning domains—Math, Code, Science, Logic, Simulation, and Tabular—each built through domain-specific reward design, deduplication, and filtering to ensure reliability and effectiveness for RL training.
            Based on Guru, we systematically revisit established findings in RL for LLM reasoning and observe significant variation across domains. For example, while prior work suggests that RL primarily elicits existing knowledge from pretrained models, our results reveal a more nuanced pattern: domains frequently seen during pretraining (Math, Code, Science) easily benefit from cross-domain RL training, while domains with limited pretraining exposure (Logic, Simulation, Tabular) require in-domain training to achieve meaningful performance gains, suggesting that RL is likely to facilitate genuine skill acquisition.
            Finally, we present Guru-7B/32B, two models that achieve state-of-the-art performance among open models RL-trained with publicly available data, outperforming best baselines by 7.9% and 6.7% on our 17-task evaluation suite across six reasoning domains. We also show that our models effectively improve the Pass@k performance of their base models, particularly on complex tasks less likely to appear in pretraining data. We release data, models, training and evaluation code to facilitate general-purpose reasoning research at our code repository.          </p>
        </div>
      </div>
    </div>
 
    </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">



    <div class="columns is-centered" style="margin-top: 0.8rem;">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Cross-Domain Reasoning Transfer</h2>
        <div class="content has-text-justified">
          <p>
            To understand how reasoning capabilities generalize with RL, we conducted controlled experiments using Guru. We investigated the impact of RL on single reasoning domains versus a mixed-domain corpus. An experimental dataset, Guru-18K (3K samples from each of the six domains), was used.
          </p>
          <h3 class="title is-4">Differential Transferability</h3>
          <img src="./static/images/fig3.svg" alt="Analysis of Cross-Domain Reasoning Transfer" style="max-width: 100%; height: auto;">

          <p>
            Math, Code, and Science benchmarks consistently improved significantly from training on other domains, possibly due to extensive exposure to these tokens during pretraining. Other domains showed limited cross-domain gains. Easier tasks within Math and Code showed positive transfer more readily than challenging benchmarks in the same domains. Mixed-domain training on a uniformly mixed dataset often matched or exceeded single-domain performance.
          </p>
          <p>
          </p>
          <h3 class="title is-4">Reward and Response-Length Dynamics </h3>
          <div class="has-text-centered" style="margin-top: 1rem; margin-bottom: 1rem;">
            <!-- <h4 class="title is-5">Reward and Response Length Analysis</h4> -->
            <img src="./static/images/reward_response_length_comparison.svg" alt="Reward and Response Length Comparison" style="max-width: 100%; height: auto;">
            <!-- <p class="is-italic" style="margin-top: 0.5rem;">Analysis of reward signals and response length changes during training.</p> -->
          </div>
          <p>In single-domain training, Code, Logic, and Tabular tasks saw contracted outputs, while Science and Math became more verbose. Joint training led to steep reward climbs initially and could reshape length dynamics.</p>
          
          <h3 class="title is-4">Effects of Training Data Difficulty</h3>
          <table border="1" cellspacing="0" cellpadding="6" style="border-collapse: collapse; text-align: center; font-family: sans-serif;">
            <thead>
              <tr style="background-color: white; font-weight: bold;">
                <th colspan="4">Math (in-domain)</th>
                <th colspan="4">Code & Tabular (cross-domain)</th>
              </tr>
              <tr style="background-color: white; font-weight: bold;">
                <th>MATH500</th>
                <th>AMC</th>
                <th>AIME24</th>
                <th></th>
                <th>HumanEval</th>
                <th>LiveCodeBench</th>
                <th>HiTab</th>
                <th>Multihiertt</th>
              </tr>
            </thead>
            <tbody>
              <tr>
                <td>75.8</td>
                <td>52.1</td>
                <td>15.8</td>
                <td style="background-color: white;"></td>
                <td>82.3</td>
                <td>11.1</td>
                <td>56.5</td>
                <td>32.0</td>
              </tr>
              <tr>
                <td>78.6</td>
                <td>58.4</td>
                <td>21.7</td>
                <td style="background-color: white;"></td>
                <td>73.1</td>
                <td>10.7</td>
                <td>53.5</td>
                <td>35.5</td>
              </tr>
              <tr style="font-weight: bold;">
                <td style="background-color: #fde0d8;">+2.8</td>
                <td style="background-color: #fcbba1;">+6.3</td>
                <td style="background-color: #fc9272;">+5.9</td>
                <td style="background-color: white;">&#x25B3; (+/-)</td>
                <td style="background-color: #9ecae1;">-9.2</td>
                <td style="background-color: #d9d9d9;">-0.4</td>
                <td style="background-color: #9ecae1;">-3.0</td>
                <td style="background-color: #fde0d8;">+3.5</td>
              </tr>
            </tbody>
          </table>
          
          <p>Training on harder math data improved in-domain math performance but could degrade performance on easier cross-domain tasks. For beneficial cross-domain transfer, a balanced distribution of difficulties or explicit inclusion of cross-domain data may be more effective.</p>
        </div>
      </div>
    </div>
    <h2 class="title is-3 has-text-centered" style="margin-top: 6rem">Data Construction</h2>
    <div class="content has-text-justified">

      <div class="columns is-centered" style="margin-top: 1rem; margin-bottom: 1rem;">
        <div class="pipeline-container" style="background: linear-gradient(135deg, #f8f9fa 0%, #e9ecef 100%); border-radius: 12px; padding: 2rem; margin: 1.5rem 0; border-left: 4px solid #007bff;">
          <!-- <h4 style="color: #2c3e50; margin-bottom: 1.5rem; font-weight: 600; text-align: center;">5-Stage Data Pipeline</h4> -->
          <div class="pipeline-steps" style="display: grid; gap: 1rem;">
            <div class="pipeline-step" style="display: flex; align-items: center; padding: 0.75rem; background: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
              <span style="background: #1e3a8a; color: white; border-radius: 50%; width: 24px; height: 24px; display: flex; align-items: center; justify-content: center; font-weight: bold; margin-right: 1rem; flex-shrink: 0;">1</span>
              <div><strong>Data Sourcing</strong> — Curating datasets across Math, Code, Science, Logic, Simulation, and Tabular domains</div>
            </div>
            <div class="pipeline-step" style="display: flex; align-items: center; padding: 0.75rem; background: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
              <span style="background: #1d4ed8; color: white; border-radius: 50%; width: 24px; height: 24px; display: flex; align-items: center; justify-content: center; font-weight: bold; margin-right: 1rem; flex-shrink: 0;">2</span>
              <div><strong>Deduplication</strong> — Removing overlapping content via substring matching (27.2% Math, 7.5% Code reduction)</div>
            </div>
            <div class="pipeline-step" style="display: flex; align-items: center; padding: 0.75rem; background: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
              <span style="background: #2563eb; color: white; border-radius: 50%; width: 24px; height: 24px; display: flex; align-items: center; justify-content: center; font-weight: bold; margin-right: 1rem; flex-shrink: 0;">3</span>
              <div><strong>Reward Design</strong> — Domain-specific verification: rule-based, execution-based, and model-based</div>
            </div>
            <div class="pipeline-step" style="display: flex; align-items: center; padding: 0.75rem; background: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
              <span style="background: #3b82f6; color: white; border-radius: 50%; width: 24px; height: 24px; display: flex; align-items: center; justify-content: center; font-weight: bold; margin-right: 1rem; flex-shrink: 0;">4</span>
              <div><strong>Heuristic Filtering</strong> — Removing noise and controlling complexity with uniform sampling</div>
            </div>
            <div class="pipeline-step" style="display: flex; align-items: center; padding: 0.75rem; background: white; border-radius: 8px; box-shadow: 0 2px 4px rgba(0,0,0,0.1);">
              <span style="background: #60a5fa; color: white; border-radius: 50%; width: 24px; height: 24px; display: flex; align-items: center; justify-content: center; font-weight: bold; margin-right: 1rem; flex-shrink: 0;">5</span>
              <div><strong>Difficulty Filtering</strong> — Selecting samples based on model performance gaps for appropriate challenge levels</div>
            </div>
          </div>
          <div style="text-align: center; margin-top: 1.5rem; padding: 1rem; background: #dbeafe; border-radius: 8px;">
            <strong style="color: #1e40af; font-size: 1.1rem;">Final Result: 92K curated examples</strong>
          </div>
        </div>
        <!-- <div class="column is-one-third has-text-centered">
          <figure class="image" style="width: 100%; margin: 0 auto; min-height: 280px;">
            <img src="./static/images/sec2_data_pipeline_v2.svg" alt="Data Pipeline Diagram" style="width: 100%; height: auto;">
          </figure>
        </div> -->
      </div>
    <div class="columns is-centered" style="margin-top: 4rem;">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">Experiment Results</h2>
        <div class="content has-text-justified">
          <p>
            We trained 7B and 32B models on the full Guru dataset to demonstrate the practical impact of multi-domain data. We used verl as the RL training framework and GRPO as the algorithm. The 7B model was trained for 2 epochs on 4 nodes (8 Hopper GPUs each) and the 32B model on 16 nodes for 2 epochs.
          </p>
          <!-- <h3 class="title is-4 has-text-centered">4.2 Results</h3> -->
          <div class="has-text-centered" style="margin-top: 1rem; margin-bottom: 1rem;">
            <!-- <h4 class="title is-5">Main </h4> -->
            <div class="table-container" style="overflow-x: auto;">
              <table id="results-table" class="table is-bordered is-narrow is-hoverable is-fullwidth is-size-7">
                <colgroup>
                  <col span="2">
                  <col class="guru-col">
                  <col span="3">
                  <col class="guru-col">
                  <col span="2">
                </colgroup>
                <thead>
                  <tr>
                    <th rowspan="2">Domain</th>
                    <th rowspan="2">Benchmarks</th>
                    <th colspan="4">7B</th>
                    <th colspan="3">32B</th>
                  </tr>
                  <tr>
                    <th>Guru 7B</th>
                    <th>General Reasoner 7B</th>
                    <th>ORZ 7B</th>
                    <th>SimpleRL 7B</th>
                    <th>Guru 32B</th>
                    <th>ORZ 32B</th>
                    <th>SimpleRL 32B</th>
                  </tr>
                </thead>
                <tbody>
                  <!-- Math -->
                  <tr>
                    <th rowspan="2">Math</th>
                    <td>AIME24(avg@32)</td><td>17.50</td><td>17.08</td><td>16.25</td><td>15.60</td><td>34.89</td><td>47.50</td><td>27.20</td>
                  </tr>
                  <tr>
                    <td>MATH500</td><td>77.25</td><td>70.40</td><td>80.80</td><td>87.00</td><td>86.00</td><td>89.80</td><td>89.60</td>
                  </tr>

                  <!-- Code -->
                  <tr>
                    <th rowspan="3">Code</th>
                    <td>LiveCodeBench(avg@4)</td><td>16.49</td><td>8.51</td><td>5.47</td><td>6.72</td><td>29.30</td><td>22.04</td><td>19.80</td>
                  </tr>
                  <tr>
                    <td>HumanEval(avg@4)</td><td>82.62</td><td>61.12</td><td>67.38</td><td>58.08</td><td>90.85</td><td>84.30</td><td>81.25</td>
                  </tr>
                  <tr>
                    <td>MBPP</td><td>70.00</td><td>39.80</td><td>48.40</td><td>49.60</td><td>78.80</td><td>74.20</td><td>76.75</td>
                  </tr>

                  <!-- Science -->
                  <tr>
                    <th rowspan="2">Science</th>
                    <td>GPQA-diamond(avg@4)</td><td>40.78</td><td>38.64</td><td>37.63</td><td>35.98</td><td>50.63</td><td>55.67</td><td>46.46</td>
                  </tr>
                  <tr>
                    <td>SuperGPQA</td><td>31.80</td><td>30.64</td><td>29.75</td><td>27.29</td><td>43.60</td><td>46.05</td><td>37.73</td>
                  </tr>

                  <!-- Logic -->
                  <tr>
                    <th rowspan="2">Logic</th>
                    <td>ARC-AGI(avg@4)</td><td>3.31</td><td>0.75</td><td>0.00</td><td>0.50</td><td>7.63</td><td>2.31</td><td>5.25</td>
                  </tr>
                  <tr>
                    <td>Zebra Puzzle(avg@4)</td><td>39.40</td><td>0.07</td><td>1.00</td><td>0.62</td><td>45.21</td><td>0.54</td><td>1.16</td>
                  </tr>

                  <!-- Simulation -->
                  <tr>
                    <th rowspan="3">Simulation</th>
                    <td>CodeI/O(avg@4)</td><td>15.63</td><td>7.13</td><td>5.13</td><td>6.63</td><td>12.63</td><td>3.75</td><td>9.75</td>
                  </tr>
                  <tr>
                    <td>CruxEval-I</td><td>61.72</td><td>63.63</td><td>69.38</td><td>56.25</td><td>80.63</td><td>71.13</td><td>72.63</td>
                  </tr>
                  <tr>
                    <td>CruxEval-O</td><td>71.28</td><td>56.50</td><td>65.88</td><td>58.31</td><td>88.75</td><td>82.38</td><td>67.75</td>
                  </tr>

                  <!-- Tabular -->
                  <tr>
                    <th rowspan="3">Tabular</th>
                    <td>FinQA</td><td>34.70</td><td>34.33</td><td>37.60</td><td>35.10</td><td>46.14</td><td>45.20</td><td>45.41</td>
                  </tr>
                  <tr>
                    <td>HiTab</td><td>74.20</td><td>54.40</td><td>54.10</td><td>50.40</td><td>82.00</td><td>63.30</td><td>69.00</td>
                  </tr>
                  <tr>
                    <td>MultiHiertt(avg@4)</td><td>44.94</td><td>31.62</td><td>38.10</td><td>37.57</td><td>55.28</td><td>52.83</td><td>52.83</td>
                  </tr>

                  <!-- Others -->
                  <tr>
                    <th rowspan="2">Others</th>
                    <td>IFEval</td><td>35.81</td><td>39.56</td><td>32.72</td><td>36.69</td><td>55.45</td><td>38.26</td><td>55.27</td>
                  </tr>
                  <tr>
                    <td>LiveBench</td><td>18.57</td><td>19.76</td><td>12.64</td><td>15.20</td><td>34.30</td><td>28.78</td><td>28.33</td>
                  </tr>

                  <!-- Average -->
                  <tr class="average-row has-background-grey-light">
                    <th colspan="2">Average Score</th><td>43.29</td><td>33.76</td><td>35.42</td><td>33.97</td><td>54.24</td><td>47.53</td><td>46.25</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <!-- <p class="is-italic" style="margin-top: 0.5rem;">Full 17 benchmark performance on 7B and 32B Models. Guru shows significant improvements over baselines on general reasoning skills.</p> -->
          </div>
          <!-- <p>
            As shown in Table 3, Guru-7B and Guru-32B consistently demonstrate more balanced and advanced performance. Guru-7B achieved an average score of 41.17%, outperforming Open-Reasoner-Zero-7B by 7.3%. Guru-32B attained 52.68%, surpassing Open-Reasoner-Zero-32B by over 7.8%. These results highlight the Guru dataset's effectiveness in promoting a wide scope of reasoning ability.
          </p> -->

          <h3 class="title is-4 has-text-centered" style="margin-top: 5rem;">Pass@k Curves</h3>
          <div class="has-text-centered" style="margin-top: 1rem; margin-bottom: 1rem;">
            <!-- <h4 class="title is-5">Main Experiment Results</h4> -->
            <div class="columns is-centered">
              <div class="column is-one-third">
                <img src="./static/images/pass_k_comparison.svg" alt="Pass@k Comparison" style="width: 100%; height: auto;">
                <!-- <p class="is-italic" style="margin-top: 0.5rem;">Pass@k analysis across different models.</p> -->
              </div>
              <div class="column is-two-thirds">
                <img src="./static/images/temp_top_comparison.svg" alt="Top Model Comparison" style="width: 100%; height: auto;">
                <!-- <p class="is-italic" style="margin-top: 0.5rem;">Performance comparison across models.</p> -->
              </div>
            </div>
          </div>
          <p>
            Pass@k behavior is highly task-dependent: while improvements in math tasks (e.g., AIME) might largely leverage base model capabilities, tasks like Zebra Puzzle demonstrate genuine reasoning expansion. Model scale also matters—larger models (32B) show more consistent gains than smaller ones (7B). Additionally, decoding hyperparameters significantly affect Pass@k, with higher temperature and top-p enhancing exploration and performance at larger k. These insights suggest Pass@k reflects both model and sampling dynamics, and should be interpreted cautiously.          </p>

        </div>
      </div>
    </div>
 
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@misc{cheng2025revisiting,
      title         = {Revisiting Reinforcement Learning for LLM Reasoning from A Cross-Domain Perspective},
      author        = {Zhoujun Cheng and Shibo Hao and Tianyang Liu and Fan Zhou and Yutao Xie and Feng Yao and Yuexin Bian and Yonghao Zhuang and Nilabjo Dey and Yuheng Zha and Yi Gu and Kun Zhou and Yuqi Wang and Yuan Li and Richard Fan and Jianshu She and Chengqian Gao and Abulhair Saparov and Haonan Li and Taylor W. Killian and Mikhail Yurochkin and Zhengzhong Liu and Eric P. Xing and Zhiting Hu},
      journal       = {arXiv preprint arXiv:2506.14965},
      year          = {2025},
      doi           = {10.48550/arXiv.2506.14965},
      url           = {https://arxiv.org/abs/2506.14965}
    }</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./Guru_Arxiv.pdf"> <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="#Guru-code-github-TODO" class="external-link">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="#placeholder-source-code-link-TODO">source code</a> of this website template,
            we just ask that you link back to the original template source if appropriate.
            Please remember to remove or update any tracking code (like Google Analytics) included in the header if you reuse this structure.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>