<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <meta name="description"
        content="GURU investigates cross-domain reinforcement learning for general reasoning in LLMs, introducing a new dataset and models.">
  <meta name="keywords" content="GURU, Reinforcement Learning, LLMs, General Reasoning, Cross-Domain Generalization, AI">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <title>GURU: Towards General Reasoning via Cross-Domain Reinforcement Learning</title>

  <script async src="https://www.googletagmanager.com/gtag/js?id=G-PYVRSFMDRL-TODO"></script>
  <script>
    window.dataLayer = window.dataLayer || [];

    function gtag() {
      dataLayer.push(arguments);
    }

    gtag('js', new Date());

    gtag('config', 'G-PYVRSFMDRL-TODO');
  </script>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
        rel="stylesheet">

  <link rel="stylesheet" href="./static/css/bulma.min.css">
  <link rel="stylesheet" href="./static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="./static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="./static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
        href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="./static/css/index.css">
  <link rel="icon" href="./static/images/favicon.svg">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script defer src="./static/js/fontawesome.all.min.js"></script>
  <script src="./static/js/bulma-carousel.min.js"></script>
  <script src="./static/js/bulma-slider.min.js"></script>
  <script src="./static/js/index.js"></script>
</head>
<body>

<nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="#GURU-project-home-TODO">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="#related-paper-1-TODO">
            Related Paper 1 - TODO
          </a>
          <a class="navbar-item" href="#GURU-dataset-details-TODO">
            GURU Dataset - TODO
          </a>
          <a class="navbar-item" href="#GURU-models-TODO">
            GURU Models - TODO
          </a>
          <a class="navbar-item" href="#future-work-TODO">
            Future Work - TODO
          </a>
        </div>
      </div>
    </div>
  </div>
</nav>

<section class="hero">
  <div class="hero-body">
    <div class="container is-max-desktop">
      <div class="columns is-centered">
        <div class="column has-text-centered">
          <h1 class="title is-1 publication-title">GURU: Towards General Reasoning via Cross-Domain Reinforcement Learning</h1>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><a href="#author-tianyang-liu-TODO">Tianyang Liu</a><sup>1,*</sup>,</span>
            <span class="author-block"><a href="#author-OpenAl-03-TODO">OpenAl 03</a><sup>2,*</sup>,</span>
            <span class="author-block"><a href="#author-Claude-Sonnet-43-TODO">Claude Sonnet 43</a><sup>3,*</sup></span>
          </div>
          <div class="is-size-5 publication-authors">
            <span class="author-block"><sup>1</sup>University of California San Diego,</span>
            <span class="author-block"><sup>2</sup>OpenAI,</span>
            <span class="author-block"><sup>3</sup>Anthropic</span>
            <br>
            <span class="author-block"><sup>*</sup>Equal Contribution</span>
            <br>
            <span class="author-block">Date: June 4, 2025</span>
          </div>
          <div class="column has-text-centered">
            <div class="publication-links">
              <span class="link-block">
                <a href="./Guru_Arxiv.pdf" class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fas fa-file-pdf"></i></span>
                  <span>Paper</span>
                </a>
              </span>
              <span class="link-block">
                <a href="https://arxiv.org/abs/XXXX.XXXXX-TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="ai ai-arxiv"></i></span>
                  <span>arXiv-TODO</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#GURU-video-link-TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-youtube"></i></span>
                  <span>Video-TODO</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#GURU-code-github-TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="fab fa-github"></i></span>
                  <span>Code-TODO</span>
                </a>
              </span>
              <span class="link-block">
                <a href="#GURU-data-link-TODO"
                   class="external-link button is-normal is-rounded is-dark">
                  <span class="icon"><i class="far fa-images"></i></span>
                  <span>Data-TODO</span>
                </a>
              </span>
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body has-text-centered">
      <img src="./static/images/Main Img.PNG" alt="Main Img.PNG" style="max-width: 100%; height: auto; margin-bottom: 1rem;">
      <h2 class="subtitle has-text-centered">
        GURU presents a systematic investigation into cross-domain RL generalization, introducing a meticulously curated 92K RL-for-reasoning dataset and models demonstrating significantly improved performance.
      </h2>
    </div>
  </div>
</section>

<section class="section">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            Achieving general reasoning in large language models (LLMs) through reinforcement learning (RL) is a significant goal, yet progress is often constrained by a limited understanding of how reasoning skills transfer across diverse domains. This paper presents a systematic investigation into cross-domain RL generalization, revealing crucial dynamics for developing broadly capable models. Our analysis shows that while domains like Math, Code, and Science, heavily represented in pretraining, gain substantially from cross-domain RL training, other areas such as Logic and Tabular primarily improve with in-domain data, highlighting domain-specific learning needs. Furthermore, we find that training on a simple mixed-domain corpus effectively enhances overall reasoning capabilities, often matching or surpassing single-domain focused training. To facilitate these investigations and foster future research, we introduce GURU, a meticulously curated 92K RL-for-reasoning dataset spanning six domains: Math, Code, Science, Logic, Simulation, and Tabular, each with corresponding verifiers. The careful construction of GURU, involving rigorous sourcing, filtering, and reward design, underpins the reliability of our cross-domain findings. Leveraging these insights and training purely with RL on GURU, our GURU-7B and GURU-32B models demonstrate significantly improved performance over leading open RL baselines, with gains of 7.3% and 7.8% respectively on an extensive 17-task, six-domain evaluation suite. We are releasing the GURU dataset, models, code, and evaluation suite to support further research towards more general RL-enhanced reasoning models.
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">1. Introduction</h2>
        <div class="content has-text-justified">
          <p>
            Recent frontier reasoning models trained with reinforcement learning (RL), such as OpenAI-01 and DeepSeek-R1, demonstrate impressive performance across diverse reasoning tasks. While many open-source efforts have attempted to unveil successful RL strategies, many analyses and training recipes are constrained to Math and Code domains. However, whether these models can be reliably extended to other domains has not been adequately established. This leaves two key questions: (1) to what extent do RL-enhanced reasoning abilities transfer between diverse domains, and (2) how can we build models that maintain high performance across these domains? A major obstacle is the lack of suitable data. Improving reasoning with RL heavily relies on the quality of the reward signal, unlike supervised fine-tuning (SFT).
          </p>
          <h3 class="title is-4">Paper Video - TODO</h3>
          <p>A video summary of the GURU paper would be here if available - TODO.</p>
        </div>
      </div>
    </div>
    </div>
</section>

<section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">2. The GURU Dataset</h2>
        <div class="content has-text-justified">
          <p>
            Datasets for Reinforcement Learning from Verifiable Rewards (RLVR) predominantly focus on narrow domains like Math and Code, often leading to overfitting. Current RLVR datasets can also suffer from redundancy, noisy queries, and poor difficulty calibration. To address these issues, we constructed a comprehensive pipeline for GURU, a multi-domain, reward-verifiable dataset.
          </p>
          <h3 class="title is-4 has-text-centered">2.1 Data Pipeline</h3>
          <p>
            Figure 2 (not provided as an image, description - TODO) presents our five-stage data curation pipeline: (1) Data Sourcing from diverse domains (Math, Code, Science, Logic, Simulation, Tabular); (2) Deduplication to ensure diversity; (3) Reward Design (rule-based, execution-based, or model-based); (4) Heuristic Filtering to remove noise; and (5) Difficulty Filtering to focus on challenging and reliable samples. The resulting GURU corpus contains 92k examples.
          </p>
          <div class="has-text-centered" style="margin-top: 1rem; margin-bottom: 1rem;">
            <h4 class="title is-5">The Guru Dataset (Table 1)</h4>
            <img src="./static/images/The Guru Dataset.PNG" alt="The Guru Dataset.PNG" style="max-width: 100%; height: auto;">
            <p class="is-italic" style="margin-top: 0.5rem;">Dataset statistics across all 6 domains.</p>
          </div>
          <p>Detailed data sources and sample scales for each domain are summarized in Table 1. For example, Math sources include OR1, DAPO, and DeepScaler. Code sources include LeetCode, TACO-Verified, PrimeIntellect, and LiveCodeBench. Science data is from WebInstruct-Verified. Logic includes existing datasets like ARC-AGI and BARC, plus synthetic tasks like Zebra Puzzle. Simulation tasks are from Code I/O (PyEdu). Tabular tasks repurpose HiTab and MultiHierTT.</p>
        </div>
      </div>
    </div>
    <div class="columns is-centered" style="margin-top: 2rem;">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">3. Analysis of Cross-Domain Reasoning Transfer</h2>
        <div class="content has-text-justified">
          <p>
            To understand how reasoning capabilities generalize with RL, we conducted controlled experiments using GURU. We investigated the impact of RL on single reasoning domains versus a mixed-domain corpus. An experimental dataset, GURU-18K (3K samples from each of the six domains), was used.
          </p>
          <div class="has-text-centered" style="margin-top: 1rem; margin-bottom: 1rem;">
            <h4 class="title is-5">Analysis of Cross-Domain Reasoning Transfer (Figure 3)</h4>
            <img src="./static/images/Analysis of Cross-Domain Reasoning Transfer.PNG" alt="Analysis of Cross-Domain Reasoning Transfer.PNG" style="max-width: 100%; height: auto;">
            <p class="is-italic" style="margin-top: 0.5rem;">RL Model Cross-Domain Transfer Performance. Heatmap shows normalized performance gains.</p>
          </div>
          <h3 class="title is-4">3.1 Differential Transferability</h3>
          <p>
            Math, Code, and Science benchmarks consistently improved significantly from training on other domains, possibly due to extensive exposure to these tokens during pretraining. Other domains showed limited cross-domain gains. Easier tasks within Math and Code showed positive transfer more readily than challenging benchmarks in the same domains.
          </p>
          <p>
            Mixed-domain training on a uniformly mixed dataset often matched or exceeded single-domain performance.
          </p>
          <h3 class="title is-4">3.2 Reward and Response-Length Dynamics - TODO</h3>
          <p>Figure 4 (not provided as an image - TODO) illustrates reward and response length. In single-domain training, Code, Logic, and Tabular tasks saw contracted outputs, while Science and Math became more verbose. Joint training led to steep reward climbs initially and could reshape length dynamics.</p>
          <h3 class="title is-4">3.3 Effects of Training Data Difficulty - TODO</h3>
          <p>Table 2 (not provided as an image - TODO) shows that training on harder math data improved in-domain math performance but could degrade performance on easier cross-domain tasks. For beneficial cross-domain transfer, a balanced distribution of difficulties or explicit inclusion of cross-domain data may be more effective.</p>
        </div>
      </div>
    </div>
    <div class="columns is-centered" style="margin-top: 2rem;">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">4. Main Experiment</h2>
        <div class="content has-text-justified">
          <p>
            We trained 7B and 32B models on the full GURU dataset to demonstrate the practical impact of multi-domain data. We used verl as the RL training framework and GRPO as the algorithm. The 7B model was trained for 2 epochs on 4 nodes (8 Hopper GPUs each) and the 32B model on 16 nodes for 2 epochs.
          </p>
          <h3 class="title is-4 has-text-centered">4.2 Results</h3>
          <div class="has-text-centered" style="margin-top: 1rem; margin-bottom: 1rem;">
            <h4 class="title is-5">Main Experiment Results (Table 3)</h4>
            <img src="./static/images/Main Experiment Results.PNG" alt="Main Experiment Results.PNG" style="max-width: 100%; height: auto;">
            <p class="is-italic" style="margin-top: 0.5rem;">Full 17 benchmark performance on 7B and 32B Models. GURU outperforms Baselines.</p>
          </div>
          <p>
            As shown in Table 3, GURU-7B and GURU-32B consistently demonstrate more balanced and advanced performance. GURU-7B achieved an average score of 41.17%, outperforming Open-Reasoner-Zero-7B by 7.3%. GURU-32B attained 52.68%, surpassing Open-Reasoner-Zero-32B by over 7.8%. These results highlight the GURU dataset's effectiveness in promoting a wide scope of reasoning ability.
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered" style="margin-top: 2rem;">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">5. Related Work</h2>
        <div class="content has-text-justified">
          <p>
            Reinforcement Learning from Verifiable Rewards (RLVR) has emerged as a powerful paradigm for LLM reasoning. Much open work has focused on specializing models for single domains like Math (Open-Reasoner-Zero, Skywork-OR1, DeepScaler, SimpleRL) or Code (DeepCoder). While powerful in specific areas, this limits generalizability. Co-current works like General-Reasoner and Nemotron-CrossThinker explore broader domains but often remain confined to STEM problems. GURU addresses this gap with a novel multi-domain dataset spanning six reasoning domains. Our GURU-7B/32B models, trained exclusively on this open data, achieve state-of-the-art general reasoning results among similar open models.
          </p>
        </div>
      </div>
    </div>
    <div class="columns is-centered" style="margin-top: 2rem;">
      <div class="column is-full-width">
        <h2 class="title is-3 has-text-centered">6. Conclusion</h2>
        <div class="content has-text-justified">
          <p>
            This work introduces GURU, a curated dataset for RL on general domains (Math, Code, Science, Logic, Simulation, Tabular analysis). Controlled experiments show that domain and task difficulty affect transferability, and mixed-domain training matches or exceeds single-domain performance. We developed GURU-7B and GURU-32B models using RL on GURU, demonstrating state-of-the-art performance among open models on an extensive evaluation suite. These models show a notable leap in general reasoning, highlighting a gap left by prior efforts. The GURU dataset, models, evaluation suite, and code will be made available to support community efforts.
          </p>
        </div>
      </div>
    </div>
    </div>
</section>

<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{liu2025guru-TODO,
  author    = {Liu, Tianyang and OpenAl 03 and Claude Sonnet 43},
  title     = {GURU: Towards General Reasoning via Cross-Domain Reinforcement Learning},
  journal   = {arXiv preprint - TODO},
  year      = {2025},
  month     = {June},
  note      = {Details based on provided PDF. Full BibTeX entry - TODO}
}</code></pre>
  </div>
</section>

<footer class="footer">
  <div class="container">
    <div class="content has-text-centered">
      <a class="icon-link"
         href="./Guru_Arxiv.pdf"> <i class="fas fa-file-pdf"></i>
      </a>
      <a class="icon-link" href="#GURU-code-github-TODO" class="external-link">
        <i class="fab fa-github"></i>
      </a>
    </div>
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This website template is licensed under a <a rel="license"
                                                href="http://creativecommons.org/licenses/by-sa/4.0/">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>
          <p>
            This means you are free to borrow the <a
              href="#placeholder-source-code-link-TODO">source code</a> of this website template,
            we just ask that you link back to the original template source if appropriate.
            Please remember to remove or update any tracking code (like Google Analytics) included in the header if you reuse this structure.
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

</body>
</html>